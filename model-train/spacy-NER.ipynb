{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12942"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('benzinga.json', \"r\") as file:\n",
    "    newsfeeds = json.load(file)\n",
    "len(newsfeeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created': '2018-05-01',\n",
       " 'title': \"21 Stocks Moving In Tuesday's Pre-Market Session\",\n",
       " 'body': \"Gainers Heat Biologics, Inc. (NASDAQ:HTBX) rose 44.9 percent to $3.10 in pre-market trading after climbing 87.72 percent on Monday. Inogen, Inc. (NASDAQ:INGN) rose 25.2 percent to $175.99 in pre-market trading following its first-quarter earnings report that saw FY18 sales guidance raised. Earnings came in at 48 cents per share, up from 27 cents per share last year. Sales came in at $79.1 million, beating estimates by $15 million. Karyopharm Therapeutics Inc. (NASDAQ:KPTI) rose 23.9 percent to $16.20 in pre-market trading following positive trial data from STORM study for selinexor. Nutrisystem, Inc. (NASDAQ:NTRI) shares rose 10.5 percent to $32.05 in pre-market trading after reporting better-than-expected Q1 earnings. Electronics for Imaging, Inc. (NASDAQ:EFII) rose 9.3 percent to $30.27 in pre-market trading following Q1 sales beat. Harmonic Inc. (NASDAQ:HLIT) rose 8.2 percent to $3.95 in pre-market trading following upbeat quarterly earnings. Intellia Therapeutics, Inc. (NASDAQ:NTLA) shares rose 7.8 percent to $21.59 in pre-market trading after reporting Q1 results. Tonix Pharmaceuticals Holding Corp. (NASDAQ:TNXP) shares rose 6.7 percent to $3.33 in pre-market trading after the company received IND clearance by the U.S. FDA for TNX-102 SL in agitation in Alzheimer's disease. Eloxx Pharmaceuticals, Inc. (NASDAQ:ELOX) rose 6.8 percent to $13.10 in pre-market trading. Eloxx Pharmaceuticals reported completion of public offering of common stock and exercise in full of underwritersâ€™ option to purchase additional shares. Tenet Healthcare Corporation (NYSE:THC) rose 5.7 percent to $25.30 in pre-market trading after the company reported stronger-than-expected results for its first quarter and raised its forecast for the year. Allison Transmission Holdings, Inc. (NYSE:ALSN) shares rose 3.5 percent to $40.35 in pre-market trading after reporting upbeat results for its first quarter on Monday. Find out what's going on in today's market and bring any questions you have to Benzinga's PreMarket Prep. Check out these big penny stock gainers and losers Losers Intevac, Inc. (NASDAQ:IVAC) fell 20.7 percent to $5.20 in pre-market trading after reporting a first-quarter sales miss. Cognex Corporation (NASDAQ:CGNX) fell 16.1 percent to $38.81 in pre-market trading following Q1 miss and downbeat Q2 sales guidance. AzurRx BioPharma, Inc. (NASDAQ:AZRX) shares fell 12 percent to $2.49 in pre-market trading after reporting an offering of common shares. Tapestry, Inc. (NYSE:TPR) shares fell 11.5 percent to $47.57 in pre-market trading after reporting Q3 results. Genprex, Inc. (NASDAQ:GNPX) fell 10.5 percent to $13.87 in pre-market trading after rising 1.84 percent on Monday. KLX Inc. (NASDAQ:KLXI) fell 7.8 percent to $72.17 in pre-market trading. Boeing Company (NYSE:BA) announced plans to acquire KLX for $4.25 billion. Intelsat S.A. (NYSE:I) fell 6.4 percent to $9.15 in pre-market trading following downbeat quarterly earnings. Archrock, Inc. (NYSE:AROC) fell 6.4 percent to $10.10 in pre-market trading after dropping 3.57 percent on Monday. Sinovac Biotech Ltd. (NASDAQ:SVA) shares fell 4.2 percent to $7.34 in pre-market trading. Sinovac has been forced to temporarily suspend flu vaccine production due to disruptive actions taken by minority shareholder of Sinovac Beijing. Cronos Group Inc. (NASDAQ:CRON) fell 4.1 percent to $6.63 in pre-market trading after gaining 1.62 percent on Monday.\",\n",
       " 'id': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsfeeds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "news_data = []\n",
    "for i in range(len(newsfeeds)):\n",
    "    news_data.append(newsfeeds[i]['body'])\n",
    "\n",
    "train_data = []\n",
    "# Extract five required labels\n",
    "for text in news_data:\n",
    "    doc = nlp(text)\n",
    "    for sent in doc.sents:\n",
    "        entities = []\n",
    "        for ent in sent.ents:\n",
    "            if ent.label_ in [\"PERSON\", \"GPE\", \"ORG\", \"PERCENT\", \"EVENT\"]:\n",
    "                # Calculate start and end character positions relative to the sentence, not the whole document\n",
    "                start_char = ent.start_char - sent.start_char\n",
    "                end_char = ent.end_char - sent.start_char\n",
    "                entities.append((start_char, end_char, ent.label_))\n",
    "        if entities:\n",
    "            train_data.append((sent.text, {\"entities\": entities}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Market Reaction Regardless of the reason for the t...\" with entities \"[(68, 72, 'ORG'), (92, 96, 'ORG'), (97, 100, 'ORG'...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Movers Indices S&P 500 ETF (NYSE:SPY) rose 2.79% t...\" with entities \"[(0, 22, 'ORG'), (28, 32, 'ORG'), (33, 36, 'ORG'),...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"FTSE/\" with entities \"[(0, 4, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"iShares FTSE/\" with entities \"[(8, 12, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"The SPDR S&P 500 ETF Trust (NYSE:SPY) is now down ...\" with entities \"[(4, 8, 'ORG'), (28, 32, 'ORG'), (33, 36, 'ORG'), ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10: Losses {'ner': 165156.10001117122}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import random\n",
    "from spacy.training.example import Example\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "nlp = spacy.blank(\"en\")  # start with a blank Language class\n",
    "nlp.add_pipe('ner')\n",
    "\n",
    "ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "# Adding labels\n",
    "for _, annotations in train_data:\n",
    "    for ent in annotations.get(\"entities\"):\n",
    "        ner.add_label(ent[2])\n",
    "\n",
    "# Initialize the weights and vocabulary\n",
    "nlp.initialize()\n",
    "\n",
    "random.seed(0)\n",
    "spacy.util.fix_random_seed(0)\n",
    "\n",
    "# Disable other components for training\n",
    "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "with nlp.disable_pipes(*unaffected_pipes):\n",
    "\n",
    "    optimizer = nlp.initialize()\n",
    "\n",
    "    for itn in range(100):\n",
    "        random.shuffle(train_data)\n",
    "        losses = {}\n",
    "        batches = minibatch(train_data, size=compounding(4., 32., 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            examples = [Example.from_dict(nlp.make_doc(text), annot) for text, annot in zip(texts, annotations)]\n",
    "            nlp.update(examples, sgd=optimizer, drop=0.5, losses=losses) \n",
    "        # print every 10 loop\n",
    "        if (itn + 1) % 10 == 0:\n",
    "            print(f'Iteration {itn + 1}: Losses', losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "output_dir = \"./model\"\n",
    "nlp.to_disk(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "# for _, annotations in train_data:\n",
    "#     for ent in annotations.get(\"entities\"):\n",
    "#         ner.add_label(ent[2])\n",
    "\n",
    "# # Fixed random seed for reproducibility\n",
    "# random.seed(0)\n",
    "# spacy.util.fix_random_seed(0)\n",
    "\n",
    "# # Disable other components for training\n",
    "# unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "# with nlp.disable_pipes(*unaffected_pipes):\n",
    "\n",
    "#     # Reduced number of iterations\n",
    "#     for itn in range(50):\n",
    "#         random.shuffle(train_data)\n",
    "#         losses = {}\n",
    "#         # Larger initial batch size\n",
    "#         batches = minibatch(train_data, size=compounding(16., 64., 1.5))\n",
    "#         for batch in batches:\n",
    "#             texts, annotations = zip(*batch)\n",
    "#             examples = [Example.from_dict(nlp.make_doc(text), annot) for text, annot in zip(texts, annotations)]\n",
    "#             nlp.update(examples, drop=0.5, losses=losses) \n",
    "#         # print every loop\n",
    "#         print(f'Iteration {itn + 1}: Losses', losses)\n",
    "\n",
    "#         # Early stopping: stop if no improvement in last 10 iterations\n",
    "#         if itn > 10 and losses['ner'] >= previous_losses['ner']:\n",
    "#             break\n",
    "#         previous_losses = losses\n",
    "\n",
    "# # Export the trained model\n",
    "# nlp.to_disk(\"./my_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# from spacy.pipeline import EntityRecognizer\n",
    "\n",
    "# # nlp = spacy.load(\"en_core_web_sm\")\n",
    "# nlp = spacy.load(\"en_core_web_md\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use first 20 articles to assure sufficient train data, data of one article is too small\n",
    "# news_data = []\n",
    "# for i in range(len(newsfeeds)):\n",
    "#     news_data.append( newsfeeds[i]['body'])\n",
    "    \n",
    "# train_data = []\n",
    "# # extract three required labels\n",
    "# for text in news_data:\n",
    "#     for sent in nlp(text).sents:\n",
    "#         entities = []\n",
    "#         for ent in sent.ents:\n",
    "#             if ent.label_ in [\"PERSON\", \"GPE\", \"ORG\"]:\n",
    "#                 entities.append((ent.start_char, ent.end_char, ent.label_))\n",
    "\n",
    "#         if entities:\n",
    "#             train_data.append((sent.text, {\"entities\": entities}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# import random\n",
    "# from spacy.training.example import Example\n",
    "# from spacy.util import minibatch, compounding\n",
    "\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "# for _, annotations in train_data:\n",
    "#     for ent in annotations.get(\"entities\"):\n",
    "#         ner.add_label(ent[2])\n",
    "\n",
    "# # Fixed random seed for reproducibility\n",
    "# random.seed(0)\n",
    "# spacy.util.fix_random_seed(0)\n",
    "\n",
    "# # Disable other components for training\n",
    "# unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "# with nlp.disable_pipes(*unaffected_pipes):\n",
    "    \n",
    "#     for itn in range(150):\n",
    "#         random.shuffle(train_data)\n",
    "#         losses = {}\n",
    "#         batches = minibatch(train_data, size=compounding(4., 32., 1.001))\n",
    "#         for batch in batches:\n",
    "#             texts, annotations = zip(*batch)\n",
    "#             examples = [Example.from_dict(nlp.make_doc(text), annot) for text, annot in zip(texts, annotations)]\n",
    "#             nlp.update(examples, drop=0.5, losses=losses) \n",
    "#         # print every 10 loop\n",
    "#         if (itn + 1) % 10 == 0:\n",
    "#             print(f'Iteration {itn + 1}: Losses', losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp.to_disk(\"./spacy-ner-mdoel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load(\"./spacy-ner-mdoel\")\n",
    "\n",
    "# doc = nlp(\"This is a sample text.\")\n",
    "# for ent in doc.ents:\n",
    "#     print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
